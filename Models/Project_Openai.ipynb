{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LEIOMCUYk6nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bf6f8b-74b5-40db-9553-0b453043dcc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq openai==0.28\n",
        "!pip install -qq transformers\n",
        "!pip install -qq pdfplumber\n",
        "!pip install -qq python-docx\n",
        "!pip install -qq transformers datasets accelerate\n",
        "!pip install -qq huggingface_hub\n",
        "!pip install -qq pymupdf\n",
        "!pip install -qq nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "i0AZMlXni9Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe76102-5552-494c-872d-a76a91247d08"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_D5otMGFUiZ",
        "outputId": "4d61d1b6-5f5e-48f4-bf3f-aa4fe0711382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: using Google CoLab\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n",
        "from typing import List\n",
        "import torch\n",
        "import gc\n",
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "    COLAB = True\n",
        "    print(\"Note: using Google CoLab\")\n",
        "except:\n",
        "    print(\"Note: not using Google CoLab\")\n",
        "    COLAB = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_ACCESS_TOKEN')"
      ],
      "metadata": {
        "id": "_XSQ3SqXdqOB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZltpasEXmuXD"
      },
      "outputs": [],
      "source": [
        "# Function to generate text using OpenAI API\n",
        "def openai_generate_text(prompt, api_key, model=\"gpt-4o-mini\", max_tokens=256, temperature=0.5):\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    try:\n",
        "        # Call OpenAI's GPT model to generate text\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=temperature\n",
        "        )\n",
        "\n",
        "        # Extract generated text from response\n",
        "        generated_text = response['choices'][0]['message']['content'].strip()\n",
        "        return generated_text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Text from Document"
      ],
      "metadata": {
        "id": "8p0j4vOoZVAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path, pipe):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    # return text\n",
        "    results = pipe(text, truncation=True, max_length=512)\n",
        "    print(results)\n",
        "    return text"
      ],
      "metadata": {
        "id": "Hxu-vVhaiNU8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Experience Only"
      ],
      "metadata": {
        "id": "xkaJl2AzYl9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_experience_only(raw_experience):\n",
        "    if isinstance(raw_experience, list):\n",
        "        raw_experience = '\\n'.join([content for _, content in raw_experience])\n",
        "\n",
        "    experience_sections = []\n",
        "    capture_experience = False\n",
        "\n",
        "    end_section_keywords = [\"Certifications\", \"Certificate\", \"Certified\", \"Work Experience\",\n",
        "                            \"Referees\", \"Skills\", \"Awards\", \"Publications\", \"Courses\", \"Conferences\", \"Memberships\"]\n",
        "    end_section_keywords = [keyword.lower() for keyword in end_section_keywords]\n",
        "    experience_keywords = [\"Professional Experience\", \"Experience\", \"Work History\", \"Work Experience\"]\n",
        "    experience_keywords = [keyword.lower() for keyword in experience_keywords]\n",
        "\n",
        "    for line in raw_experience.split('\\n'):\n",
        "        line_clean = line.strip()\n",
        "        if not line_clean:\n",
        "            continue\n",
        "\n",
        "        if any(keyword in line.lower() for keyword in experience_keywords):\n",
        "            capture_experience = True\n",
        "            continue\n",
        "\n",
        "        if any(keyword in line.lower() for keyword in end_section_keywords):\n",
        "            capture_experience = False\n",
        "\n",
        "        if capture_experience:\n",
        "            experience_sections.append(line_clean)\n",
        "\n",
        "    return experience_sections\n"
      ],
      "metadata": {
        "id": "mA_a9Pp1ujga"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_job_titles(resume, api_key):\n",
        "    jobs = openai_generate_text(f\"Extract the job titles, period they were held and location from this resume: '{resume}'\", api_key)\n",
        "    return jobs"
      ],
      "metadata": {
        "id": "1ziEMt6sD9ZA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the question-answering pipeline\n",
        "def get_candidate_name(resume_text):\n",
        "    qa_pipe = pipeline(\"question-answering\", model=\"Kiet/autotrain-resume_parser-1159242747\")\n",
        "    question = \"What is the candidate's name?\"\n",
        "    result = qa_pipe(question=question, context=resume_text)\n",
        "    answer = result['answer']\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "QxKO154Dxwbk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl9Jr_tkv1Sa"
      },
      "source": [
        "## Prepare output document"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from docx import Document\n",
        "from docx.shared import Pt, Inches\n",
        "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "from docx.enum.text import WD_LINE_SPACING\n",
        "from docx.shared import Cm\n",
        "import re"
      ],
      "metadata": {
        "id": "Y5HSSpuX7MMz"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import re\n",
        "# from docx import Document\n",
        "# from docx.shared import Cm, Pt\n",
        "# from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
        "\n",
        "# def create_resume_doc(jobs, refined, name, education, profile, file_name=\"Refined_Resume.docx\"):\n",
        "#     # Create a new Document\n",
        "#     doc = Document()\n",
        "\n",
        "#     # Set the document to A4 size\n",
        "#     section = doc.sections[0]\n",
        "#     section.page_height = Cm(29.7)\n",
        "#     section.page_width = Cm(21.0)\n",
        "\n",
        "#     # Set margins for A4\n",
        "#     section.left_margin = Cm(2)\n",
        "#     section.right_margin = Cm(2)\n",
        "#     section.top_margin = Cm(2)\n",
        "#     section.bottom_margin = Cm(2)\n",
        "\n",
        "\n",
        "#     # Title of the Resume\n",
        "#     title = doc.add_heading(\"RESUME\", level=1)\n",
        "#     title.paragraph_format.space_after = Pt(0)\n",
        "#     title.paragraph_format.space_before = Pt(0)\n",
        "#     title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
        "#     name_paragraph = doc.add_paragraph(name)\n",
        "#     name_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
        "\n",
        "#     # Profile Section\n",
        "#     if profile:\n",
        "#         doc.add_paragraph(\"Profile\", style='Heading 2')\n",
        "#         achievement_lines = profile.split(\"\\n\")\n",
        "#         for line in achievement_lines:\n",
        "#             if line.strip():\n",
        "#                 paragraph = doc.add_paragraph(line.strip())\n",
        "#                 paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
        "\n",
        "#     # Add Experience Section to document\n",
        "#     doc.add_paragraph(\"Tailored Experience\", style='Heading 2')\n",
        "#     experience_lines = refined.split(\"\\n\")\n",
        "#     for line in experience_lines:\n",
        "#         cleaned_line = line.strip()\n",
        "\n",
        "#         if cleaned_line.lower() == \"experience\" or not cleaned_line:\n",
        "#             continue\n",
        "\n",
        "#         cleaned_line = re.sub(r'[^\\w\\s\\,–-]', '', cleaned_line)\n",
        "\n",
        "#         # Check if the line is a job title\n",
        "#         paragraph = None\n",
        "#         if any(job in cleaned_line for job in jobs):\n",
        "#             paragraph = doc.add_paragraph(cleaned_line)\n",
        "#             paragraph.paragraph_format.space_after = Pt(0)\n",
        "\n",
        "#         else:\n",
        "#             if len(cleaned_line) > 3:\n",
        "#                 paragraph = doc.add_paragraph(cleaned_line, style='List Bullet')\n",
        "\n",
        "#         if paragraph:\n",
        "#             paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
        "\n",
        "#     # Add Education section to the document\n",
        "#     doc.add_paragraph(\"Education\", style='Heading 2')\n",
        "#     education_lines = education.split(\"\\n\")\n",
        "#     for line in education_lines:\n",
        "#         if line.strip():\n",
        "#             cleaned_line = line.lstrip('- ').strip()\n",
        "#             paragraph = doc.add_paragraph(cleaned_line)\n",
        "#             paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
        "\n",
        "#     # Save the document\n",
        "#     doc.save(file_name)\n",
        "#     print(f\"Document saved as {file_name}\")\n"
      ],
      "metadata": {
        "id": "K3PXFqV-uWtA"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_experience_section(doc, refined, jobs):\n",
        "    doc.add_paragraph(\"Tailored Experience\", style='Heading 2')\n",
        "\n",
        "    if refined:\n",
        "        experience_lines = refined.split(\"\\n\")\n",
        "\n",
        "        first_line = experience_lines[0].strip().lower()\n",
        "        if \"experience\" in first_line or \"heres a refined experience section\" in first_line:\n",
        "            experience_lines = experience_lines[1:]\n",
        "\n",
        "        for line in experience_lines:\n",
        "            cleaned_line = line.strip()\n",
        "            paragraph = None\n",
        "\n",
        "            if cleaned_line.lower() == \"experience\" or len(cleaned_line) < 2:\n",
        "                continue\n",
        "\n",
        "            cleaned_line = re.sub(r'[^\\w\\s,–-•]', '', cleaned_line)\n",
        "\n",
        "            if any(job.lower() in cleaned_line.lower() for job in jobs):\n",
        "                paragraph = doc.add_paragraph()\n",
        "                run = paragraph.add_run(cleaned_line)\n",
        "                # run.bold = True\n",
        "\n",
        "            else:\n",
        "                if len(cleaned_line) > 3:\n",
        "                    paragraph = doc.add_paragraph(cleaned_line, style='List Bullet')\n",
        "                    run = paragraph.add_run()\n",
        "                    run.italic = True\n",
        "\n",
        "            if paragraph:\n",
        "                paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
        "                paragraph.paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE"
      ],
      "metadata": {
        "id": "NPnVeqjW2fuO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_education_section(doc, education):\n",
        "    if education:\n",
        "        education_lines = education.split(\"\\n\")\n",
        "\n",
        "        current_entry = []\n",
        "\n",
        "        for line in education_lines:\n",
        "            cleaned_line = re.sub(r'[^\\w\\s,–-]', '', line).strip()\n",
        "\n",
        "            if not cleaned_line:\n",
        "                continue\n",
        "\n",
        "            if \"MSc\" in cleaned_line or \"BSc\" in cleaned_line:\n",
        "                if current_entry:\n",
        "                    add_education_paragraph(doc, current_entry)\n",
        "                    current_entry = []\n",
        "\n",
        "            current_entry.append(cleaned_line)\n",
        "\n",
        "        if current_entry:\n",
        "            add_education_paragraph(doc, current_entry)\n",
        "\n",
        "def add_education_paragraph(doc, entry_lines):\n",
        "    paragraph = doc.add_paragraph(style=None)\n",
        "    for i, line in enumerate(entry_lines):\n",
        "        run = paragraph.add_run(line)\n",
        "        # run.italic = True\n",
        "\n",
        "        if i < len(entry_lines) - 1:\n",
        "            run.add_break()\n",
        "\n",
        "    paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
        "    paragraph.paragraph_format.line_spacing_rule = WD_LINE_SPACING.SINGLE\n",
        "    paragraph.paragraph_format.space_after = Pt(12)\n"
      ],
      "metadata": {
        "id": "aRjIzCKkyCzv"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ZiANtG7av0RW"
      },
      "outputs": [],
      "source": [
        "def create_resume_doc(jobs, refined, name, education, profile, file_name=\"Refined_Resume.docx\"):\n",
        "    # Create a new Document\n",
        "    doc = Document()\n",
        "\n",
        "    # Set the document to A4 size\n",
        "    section = doc.sections[0]\n",
        "    section.page_height = Cm(29.7)\n",
        "    section.page_width = Cm(21.0)\n",
        "    section.font_size = Pt(12)\n",
        "    section.font_name = 'Times New Roman'\n",
        "\n",
        "    # Set margins for A4\n",
        "    section.left_margin = Cm(2)\n",
        "    section.right_margin = Cm(2)\n",
        "    section.top_margin = Cm(2)\n",
        "    section.bottom_margin = Cm(2)\n",
        "\n",
        "\n",
        "    # Title and Name of the Resume\n",
        "    title = doc.add_heading(\"RESUME\", level=1)\n",
        "    title.paragraph_format.space_after = Pt(0)\n",
        "    title.paragraph_format.space_before = Pt(0)\n",
        "    title.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
        "    name = doc.add_paragraph(name)\n",
        "    name.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
        "    name.paragraph_format.space_after = Pt(0)\n",
        "    name.paragraph_format.space_before = Pt(0)\n",
        "\n",
        "    # Add Profile Section\n",
        "    if profile:\n",
        "        doc.add_paragraph(\"Profile\", style='Heading 2')\n",
        "        achievement_lines = profile.split(\"\\n\")\n",
        "        for line in achievement_lines:\n",
        "            if line.strip():\n",
        "                paragraph = doc.add_paragraph(line.strip())\n",
        "                paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.JUSTIFY\n",
        "\n",
        "    # Add Experience Section to document\n",
        "    add_experience_section(doc, refined, jobs)\n",
        "\n",
        "    # Add Education section to the document\n",
        "    doc.add_paragraph(\"Education\", style='Heading 2')\n",
        "    add_education_section(doc, education)\n",
        "\n",
        "    # Save the document\n",
        "    doc.save(file_name)\n",
        "    print(f\"Document saved as {file_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    api_key = userdata.get('OPENAI_API_KEY')\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Extract text from documents\n",
        "    extract_pipeline = pipeline(\"text-classification\", model=\"nikunjbjj/jd-resume-model\", device=device)\n",
        "    resume_pdf_path = \"Pauline Korukundo Resume 2024.pdf\"\n",
        "    resume = extract_text_from_pdf(resume_pdf_path, extract_pipeline)\n",
        "    job_descr_pdf_path = \"software_eng_1_yr.pdf\"\n",
        "    job_descr = extract_text_from_pdf(job_descr_pdf_path, extract_pipeline)\n",
        "\n",
        "    # Generate a profile summary\n",
        "    profile_prompt = (\n",
        "        f\"Generate a brief, two-sentence professional summary highlighting key skills and experiences from the resume. \"\n",
        "        f\"Focus on achievements relevant to a software engineering role. Avoid including a title: '{resume}'\"\n",
        "    )\n",
        "    profile = openai_generate_text(profile_prompt, api_key)\n",
        "\n",
        "    # Extract and refine experience to match job description\n",
        "    get_experience = extract_experience_only(resume)\n",
        "    refined_exp_prompt = (\n",
        "        f\"Refine the experience section of this resume to match the requirements in the job description. \"\n",
        "        f\"Summarize each position with a maximum of 3 bullet points, focusing on achievements, skills, or responsibilities most relevant to the job: '{job_descr}'. \"\n",
        "        f\"Here is the experience to be refined: '{get_experience}'\"\n",
        "    )\n",
        "    refined_exp = openai_generate_text(refined_exp_prompt, api_key)\n",
        "\n",
        "    # Extract education details\n",
        "    education_prompt = (\n",
        "        f\"Extract the education details from this resume. For each institution, list the degree, institution name, dates attended, and completion status. \"\n",
        "        f\"Format each entry as a bullet point, with the completion status appearing at the end of each entry: '{resume}'\"\n",
        "    )\n",
        "    education = openai_generate_text(education_prompt, api_key)\n",
        "\n",
        "    # Extract job titles for formatting\n",
        "    jobs = get_job_titles(resume, api_key)\n",
        "\n",
        "    # Extract candidate name\n",
        "    name = get_candidate_name(resume)\n",
        "\n",
        "    # Generate the new resume document\n",
        "    create_resume_doc(jobs, refined_exp, name, education, profile)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plPUaQJ4ri8X",
        "outputId": "d21098b7-326f-42a6-c7ab-efbce0e0f7a4"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POS', 'score': 0.4816814064979553}]\n",
            "[{'label': 'POS', 'score': 0.5531230568885803}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Kiet/autotrain-resume_parser-1159242747 were not used when initializing LongformerForQuestionAnswering: ['longformer.embeddings.position_ids']\n",
            "- This IS expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document saved as Refined_Resume.docx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}