# -*- coding: utf-8 -*-
"""Resume_similarity_score (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16MnyGQsl3G9pO7uF9_I8DxNvYyCXr04H
"""

!pip install sentence-transformers
!pip install scikit-learn

from sentence_transformers import SentenceTransformer

# Load the pre-trained model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

def read_file(file_path):
    with open(file_path, 'r') as file:
        return file.read()

!pip install python-docx
!pip install PyPDF2

import os
import PyPDF2
from docx import Document
#Import the required submodule
from docx.opc.exceptions import PackageNotFoundError

def read_file(file_path):
    """
    Reads the content of a file. If the file is a PDF, it extracts the text using PyPDF2.
    If the file is a docx, it extracts the text using python-docx.
    Otherwise, it reads the file as a text file, trying different encodings if 'utf-8' fails.
    """

    # Check if the file exists before proceeding
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    if file_path.lower().endswith('.pdf'):
        with open(file_path, 'rb') as file:  # Open in binary read mode for PDFs
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page_num in range(len(reader.pages)):
                page = reader.pages[page_num]
                text += page.extract_text()
            return text
    elif file_path.lower().endswith('.docx'):
        # Handle docx files using python-docx
        try:
            doc = Document(file_path)
            text = ""
            for paragraph in doc.paragraphs:
                text += paragraph.text + "\n"  # Add newline for paragraph separation
            return text
        # Use the imported exception class
        except PackageNotFoundError:
            # Provide a more informative error message if the file is not a valid docx
            raise PackageNotFoundError(f"The file {file_path} is not a valid docx file. It may be corrupted or of a different format.")

jd_text = read_file('/content/sample_data/Data_analyst_jd.docx')  # Replace with actual file path
resume_text = read_file('/content/sample_data/Deekshitha_Reddy_Muppidi_Resume.docx')  # Replace with actual file path

# Generate embeddings for both JD and resume using the pre-trained model
jd_embedding = model.encode([jd_text])
resume_embedding = model.encode([resume_text])

from sklearn.metrics.pairwise import cosine_similarity

# Compute cosine similarity between the embeddings
similarity_score = cosine_similarity(jd_embedding, resume_embedding)[0][0]

# Convert to percentage
similarity_percentage = similarity_score * 100  # Convert similarity to percentage

def main(jd_file, resume_file):
    try:
        # Read the JD and resume files
        jd_text = read_file(jd_file)
        resume_text = read_file(resume_file)

        # Generate embeddings for both JD and resume using the pre-trained model
        jd_embedding = model.encode([jd_text])
        resume_embedding = model.encode([resume_text])

        # Compute cosine similarity between the embeddings
        similarity_score = cosine_similarity(jd_embedding, resume_embedding)[0][0]

        # Return similarity score as a percentage
        return similarity_score * 100  # Convert to percentage

    except Exception as e:
        print(f"Error: {e}")
        return None

if __name__ == "__main__":
    jd_file = '/content/sample_data/Data_analyst_jd.docx'  # Replace with actual file path
    resume_file = '/content/sample_data/Deekshitha_Reddy_Muppidi_Resume.docx'  # Replace with actual file path

    # Get the similarity score
    result = main(jd_file, resume_file)

    # Display the result
    if result is not None:
        print(f"Similarity Score: {result:.2f}%")
    else:
        print("There was an error in processing the files.")