{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNZuoqwRQDYT",
        "outputId": "f4936377-6320-4fa9-df1a-8c526039e7f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the pre-trained model\n",
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n"
      ],
      "metadata": {
        "id": "qkeDvTHXQJT-"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return file.read()"
      ],
      "metadata": {
        "id": "xgug9FHUQPB8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCoh6StGnZfA",
        "outputId": "5a19f970-fcb6-424e-c42c-4c70593431d5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "from docx import Document\n",
        "#Import the required submodule\n",
        "from docx.opc.exceptions import PackageNotFoundError\n",
        "\n",
        "def read_file(file_path):\n",
        "    \"\"\"\n",
        "    Reads the content of a file. If the file is a PDF, it extracts the text using PyPDF2.\n",
        "    If the file is a docx, it extracts the text using python-docx.\n",
        "    Otherwise, it reads the file as a text file, trying different encodings if 'utf-8' fails.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if the file exists before proceeding\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "\n",
        "    if file_path.lower().endswith('.pdf'):\n",
        "        with open(file_path, 'rb') as file:  # Open in binary read mode for PDFs\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num in range(len(reader.pages)):\n",
        "                page = reader.pages[page_num]\n",
        "                text += page.extract_text()\n",
        "            return text\n",
        "    elif file_path.lower().endswith('.docx'):\n",
        "        # Handle docx files using python-docx\n",
        "        try:\n",
        "            doc = Document(file_path)\n",
        "            text = \"\"\n",
        "            for paragraph in doc.paragraphs:\n",
        "                text += paragraph.text + \"\\n\"  # Add newline for paragraph separation\n",
        "            return text\n",
        "        # Use the imported exception class\n",
        "        except PackageNotFoundError:\n",
        "            # Provide a more informative error message if the file is not a valid docx\n",
        "            raise PackageNotFoundError(f\"The file {file_path} is not a valid docx file. It may be corrupted or of a different format.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "AFUTo8CVnbxo"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jd_text = read_file('/content/sample_data/Data_analyst_jd.docx')  # Replace with actual file path\n",
        "resume_text = read_file('/content/sample_data/Deekshitha_Reddy_Muppidi_Resume.docx')  # Replace with actual file path\n",
        "\n",
        "# Generate embeddings for both JD and resume using the pre-trained model\n",
        "jd_embedding = model.encode([jd_text])\n",
        "resume_embedding = model.encode([resume_text])\n"
      ],
      "metadata": {
        "id": "Xcgd4k9RRlsw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute cosine similarity between the embeddings\n",
        "similarity_score = cosine_similarity(jd_embedding, resume_embedding)[0][0]\n",
        "\n",
        "# Convert to percentage\n",
        "similarity_percentage = similarity_score * 100  # Convert similarity to percentage\n"
      ],
      "metadata": {
        "id": "KZ4cZ_zdQeop"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(jd_file, resume_file):\n",
        "    try:\n",
        "        # Read the JD and resume files\n",
        "        jd_text = read_file(jd_file)\n",
        "        resume_text = read_file(resume_file)\n",
        "\n",
        "        # Generate embeddings for both JD and resume using the pre-trained model\n",
        "        jd_embedding = model.encode([jd_text])\n",
        "        resume_embedding = model.encode([resume_text])\n",
        "\n",
        "        # Compute cosine similarity between the embeddings\n",
        "        similarity_score = cosine_similarity(jd_embedding, resume_embedding)[0][0]\n",
        "\n",
        "        # Return similarity score as a percentage\n",
        "        return similarity_score * 100  # Convert to percentage\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "h_fBXH74Qjgh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    jd_file = '/content/sample_data/Data_analyst_jd.docx'  # Replace with actual file path\n",
        "    resume_file = '/content/sample_data/Deekshitha_Reddy_Muppidi_Resume.docx'  # Replace with actual file path\n",
        "\n",
        "    # Get the similarity score\n",
        "    result = main(jd_file, resume_file)\n",
        "\n",
        "    # Display the result\n",
        "    if result is not None:\n",
        "        print(f\"Similarity Score: {result:.2f}%\")\n",
        "    else:\n",
        "        print(\"There was an error in processing the files.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPtMsIncQkdR",
        "outputId": "35508fc6-a777-4660-b9f6-0ef21d85bb06"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Score: 38.55%\n"
          ]
        }
      ]
    }
  ]
}