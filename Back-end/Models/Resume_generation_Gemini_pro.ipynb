{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive,userdata"
      ],
      "metadata": {
        "id": "TGCJ9so8SCQG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrc67y5tSFUN",
        "outputId": "4fccaa81-2f8a-46d3-c1b9-a44103c7d821"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYL-S9AYSOWd",
        "outputId": "8e549cca-b3c6-4f98-bbeb-eaf44f3f1246",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m507.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dEQVW-vSR23",
        "outputId": "aae044aa-2c11-4f12-f58d-90347925b434",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/232.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdhxr8TUSfqP",
        "outputId": "3e41d685-54b0-4dc2-d4e2-072dee3d89f5",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_google_genai -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRVRoBz_SrFO",
        "outputId": "3d945c3d-c524-4db5-80a7-432de5bd9a5e",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psD7c5R_VumT",
        "outputId": "de5dc998-cbbc-4b92-8f39-cccde7086041"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/244.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install docx2txt -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oO5vt4FWEYE",
        "outputId": "047b1d99-1f84-4d64-8f81-3ad752162d85"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2sYtTxhY6Ug",
        "outputId": "f874f5c5-fdc5-448b-89ed-d8b1e118ea80"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai -qq\n"
      ],
      "metadata": {
        "id": "1oadHS13ZiwF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-generativeai -qq\n"
      ],
      "metadata": {
        "id": "q98Io5vMccNh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import docx2txt\n",
        "def extract_text(file_path):\n",
        "    if file_path.endswith(\".docx\"):\n",
        "        # Extract text from DOCX file\n",
        "        return docx2txt.process(file_path)\n",
        "\n",
        "    elif file_path.endswith(\".pdf\"):\n",
        "        # Extract text from PDF file\n",
        "        text = \"\"\n",
        "        with open(file_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page_num in range(len(reader.pages)):\n",
        "                text += reader.pages[page_num].extract_text()\n",
        "        return text\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type\")"
      ],
      "metadata": {
        "id": "dcTP4b9MWC7q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "wJFEM_1dWsMB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/drive/MyDrive/Resume/firm-capsule-436804-b5-5f553d9f1043.json\"\n"
      ],
      "metadata": {
        "id": "My2v_9FnYWkz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install python-docx"
      ],
      "metadata": {
        "id": "cNVwqu3pgu2S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import streamlit as st\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores.faiss import FAISS\n",
        "from google.colab import drive\n",
        "from docx import Document\n",
        "import google.generativeai as genai\n",
        "from datetime import datetime\n",
        "\n",
        "api_key_google = userdata.get('google_cloud')\n",
        "genai.configure(api_key=api_key_google)\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WwbAOJqYc7Ab",
        "outputId": "6581fd70-6501-404e-afbb-bf66a741ef45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_resume_to_docx(tailored_resume, file_path):\n",
        "    doc = Document()\n",
        "    doc.add_heading('Tailored Resume', level=1)\n",
        "    doc.add_paragraph(tailored_resume)\n",
        "    doc.save(file_path)\n"
      ],
      "metadata": {
        "id": "yTIipa4QgM-I"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to read text from a .docx file\n",
        "def read_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    return \"\\n\".join([para.text for para in doc.paragraphs])"
      ],
      "metadata": {
        "id": "FY-h1S01jPcE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_resume_text(resume_text):\n",
        "    prompt = f\"\"\"\n",
        "Given the following resume content:\n",
        "\n",
        "[Resume Start]\n",
        "{resume_text}\n",
        "[Resume End]\n",
        "\n",
        "Format this resume content with appropriate section titles. Only use the information provided and avoid placeholders like \"[Your Name]\". Ensure it retains the structure and details exactly as shown.\n",
        "\"\"\"\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        print(response)\n",
        "        # Accessing the generated text content\n",
        "        return response.candidates[0].content.parts[0].text\n",
        "    except Exception as e:\n",
        "        print(\"Error in generating resume text:\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "nc9UhoF_jr9T"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tailor_resume(resume_text, job_description):\n",
        "    # Use the generate_resume_text function to get the formatted resume content\n",
        "    formatted_resume = generate_resume_text(resume_text)\n",
        "    print(\"formatted resume:\",formatted_resume)\n",
        "    if formatted_resume:\n",
        "        prompt = f\"\"\"\n",
        "Below is the candidate's original formatted resume content:\n",
        "\n",
        "[Resume Start]\n",
        "{formatted_resume}\n",
        "[Resume End]\n",
        "\n",
        "Using the candidate's resume above and the job description below, create a tailored resume.\n",
        "\n",
        "[Job Description Start]\n",
        "{job_description}\n",
        "[Job Description End]\n",
        "\n",
        "Please generate a resume that:\n",
        "1. Uses real data from the candidate's resume, including name, education, and specific skills.\n",
        "2. Avoids placeholders like \"[Your Name]\" and includes actual details.\n",
        "3. Emphasizes experiences that are directly relevant to the job description.\n",
        "\"\"\"\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            return response.candidates[0].content.parts[0].text\n",
        "        except Exception as e:\n",
        "            print(\"Error in tailoring resume:\", e)\n",
        "            return None\n",
        "    else:\n",
        "        return \"Failed to generate resume text.\""
      ],
      "metadata": {
        "id": "c3D6kxehjusS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function for Streamlit app\n",
        "def main():\n",
        "    st.header('Resume Tailoring')\n",
        "\n",
        "    # Load the resume and job description from Google Drive\n",
        "    resume_text = read_docx(\"/content/drive/MyDrive/Resume/Anushka_Bhat_latest.docx\")\n",
        "    job_description = read_docx(\"/content/drive/MyDrive/Resume/Job_description.docx\")\n",
        "\n",
        "    # Tailor resume based on job description\n",
        "    tailored_resume = tailor_resume(resume_text, job_description)\n",
        "    st.write(\"**Tailored Resume:**\")\n",
        "    st.write(tailored_resume)\n",
        "    print(tailored_resume)\n",
        "\n",
        "        # Save the tailored resume to a .docx file\n",
        "    if tailored_resume:\n",
        "        file_path = f\"Tailored_Resume_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx\"\n",
        "        save_resume_to_docx(tailored_resume, file_path)\n",
        "        st.success(f\"Tailored resume saved to {file_path}\")"
      ],
      "metadata": {
        "id": "YOYI1Ehxjx9b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TjlKiBbmj0Nt",
        "outputId": "6f1fd315-0324-48d5-e2b9-db315cdbc1f6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-05 01:56:12.910 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:13.570 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-11-05 01:56:13.573 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:22.835 200 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 6303.59ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"text\": \"**Anushka Bhat**\\n\\n**Contact Information**\\n* Email: anushkabhat9@gmail.com\\n* LinkedIn: anushkabhat07\\n* Phone: 1-260-515-4301\\n\\n**Summary**\\nOver 7.5 years of experience in Database and Business Intelligence applications development. Currently pursuing a Master's in Computer Science at Purdue University Fort Wayne, specializing in Machine Learning and Deep Learning.\\n\\n**Education**\\n**Master of Science in Computer Science**\\nPurdue University Fort Wayne, Fort Wayne, IN\\n* Machine Learning, Natural Language Processing, Software Engineering, Web Development, Database Management Systems, Corporate Partners\\n* GPA: 4.0\\n* 2023-2025\\n\\n**Bachelor of Engineering in Computer Science**\\nFirst Class\\n2011-2015\\n\\n**Languages and Technologies**\\n* Azure SQL, T-SQL, Python, HTML, CSS, JavaScript\\n* Azure Data Factory, MSBI (SSIS, SSRS, SSAS), Power BI, Alteryx\\n\\n**Work Experience**\\n**Ernst & Young Texas, USA**\\n* Tax Technology Intern\\n* Jun 2024 - Aug 2024\\n\\n**Ernst & Young GDS, India**\\n* Tax Senior\\n* Sept 2019 - Aug 2023\\n\\n**Bitwise Solutions, India**\\n* Programmer Analyst\\n* April 2018 - July 2019\\n\\n**Tech Mahindra Ltd., India**\\n* Associate Software Engineer\\n* Aug 2015 - Mar 2018\\n\\n**Rewards and Recognition**\\n* SPOT Award - For Excellent performance, ownership, and quality throughout the year 2021\\n* Extra Miler - For demonstrating quick learning capabilities and result-oriented performance in the quarter Jan-Mar 2020\"\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"index\": 0,\n",
            "          \"safety_ratings\": [\n",
            "            {\n",
            "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
            "              \"probability\": \"NEGLIGIBLE\"\n",
            "            },\n",
            "            {\n",
            "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
            "              \"probability\": \"NEGLIGIBLE\"\n",
            "            },\n",
            "            {\n",
            "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
            "              \"probability\": \"NEGLIGIBLE\"\n",
            "            },\n",
            "            {\n",
            "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
            "              \"probability\": \"NEGLIGIBLE\"\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 909,\n",
            "        \"candidates_token_count\": 399,\n",
            "        \"total_token_count\": 1308\n",
            "      }\n",
            "    }),\n",
            ")\n",
            "formatted resume: **Anushka Bhat**\n",
            "\n",
            "**Contact Information**\n",
            "* Email: anushkabhat9@gmail.com\n",
            "* LinkedIn: anushkabhat07\n",
            "* Phone: 1-260-515-4301\n",
            "\n",
            "**Summary**\n",
            "Over 7.5 years of experience in Database and Business Intelligence applications development. Currently pursuing a Master's in Computer Science at Purdue University Fort Wayne, specializing in Machine Learning and Deep Learning.\n",
            "\n",
            "**Education**\n",
            "**Master of Science in Computer Science**\n",
            "Purdue University Fort Wayne, Fort Wayne, IN\n",
            "* Machine Learning, Natural Language Processing, Software Engineering, Web Development, Database Management Systems, Corporate Partners\n",
            "* GPA: 4.0\n",
            "* 2023-2025\n",
            "\n",
            "**Bachelor of Engineering in Computer Science**\n",
            "First Class\n",
            "2011-2015\n",
            "\n",
            "**Languages and Technologies**\n",
            "* Azure SQL, T-SQL, Python, HTML, CSS, JavaScript\n",
            "* Azure Data Factory, MSBI (SSIS, SSRS, SSAS), Power BI, Alteryx\n",
            "\n",
            "**Work Experience**\n",
            "**Ernst & Young Texas, USA**\n",
            "* Tax Technology Intern\n",
            "* Jun 2024 - Aug 2024\n",
            "\n",
            "**Ernst & Young GDS, India**\n",
            "* Tax Senior\n",
            "* Sept 2019 - Aug 2023\n",
            "\n",
            "**Bitwise Solutions, India**\n",
            "* Programmer Analyst\n",
            "* April 2018 - July 2019\n",
            "\n",
            "**Tech Mahindra Ltd., India**\n",
            "* Associate Software Engineer\n",
            "* Aug 2015 - Mar 2018\n",
            "\n",
            "**Rewards and Recognition**\n",
            "* SPOT Award - For Excellent performance, ownership, and quality throughout the year 2021\n",
            "* Extra Miler - For demonstrating quick learning capabilities and result-oriented performance in the quarter Jan-Mar 2020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-05 01:56:29.854 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.856 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.857 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.858 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.860 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.864 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.865 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.865 200 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 7022.26ms\n",
            "2024-11-05 01:56:29.866 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.948 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 01:56:29.951 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Anushka Bhat**\n",
            "\n",
            "**Contact Information**\n",
            "* Email: anushkabhat9@gmail.com\n",
            "* LinkedIn: anushkabhat07\n",
            "* Phone: 1-260-515-4301\n",
            "\n",
            "**Summary**\n",
            "Engineering student with 7.5+ years of experience in manufacturing process improvement, problem-solving, and data analysis. Proven ability to identify and implement cost-saving initiatives.\n",
            "\n",
            "**Education**\n",
            "* **Master of Science in Computer Science**\n",
            "Purdue University Fort Wayne, Fort Wayne, IN\n",
            "* Specialization in Machine Learning and Deep Learning\n",
            "* GPA: 4.0\n",
            "* 2023-2025\n",
            "\n",
            "* **Bachelor of Engineering in Computer Science**\n",
            "First Class\n",
            "2011-2015\n",
            "\n",
            "**Skills**\n",
            "* Process Improvement (Lean Manufacturing, Cycle Time Reduction)\n",
            "* Problem-Solving and Troubleshooting\n",
            "* Statistical Analysis and Data Visualization\n",
            "* Manufacturing Equipment Installation and Upgrades\n",
            "* MS Office Suite\n",
            "* Python, HTML, CSS, JavaScript\n",
            "\n",
            "**Experience**\n",
            "* **Tax Senior**\n",
            "Ernst & Young GDS, India\n",
            "* Sept 2019 - Aug 2023\n",
            "* Implemented cost-saving measures by automating data extraction and analysis processes, resulting in a 15% reduction in operational expenses.\n",
            "\n",
            "* **Programmer Analyst**\n",
            "Bitwise Solutions, India\n",
            "* April 2018 - July 2019\n",
            "* Identified manufacturing bottlenecks and implemented process improvements that increased production efficiency by 10%.\n",
            "\n",
            "* **Associate Software Engineer**\n",
            "Tech Mahindra Ltd., India\n",
            "* Aug 2015 - Mar 2018\n",
            "* Assisted in the implementation of new manufacturing equipment, leading to improved product quality and reduced production lead times.\n",
            "\n",
            "**Awards and Recognition**\n",
            "* SPOT Award - For Excellent performance, ownership, and quality throughout the year 2021\n",
            "* Extra Miler - For demonstrating quick learning capabilities and result-oriented performance in the quarter Jan-Mar 2020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eQe_Mbduj4FB"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}